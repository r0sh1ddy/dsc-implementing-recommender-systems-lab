{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice creating a recommender system model using `surprise`. You'll also get the chance to create a more complete recommender system pipeline to obtain the top recommendations for a specific user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Use surprise's built-in reader class to process data to work with recommender algorithms \n",
    "- Obtain a prediction for a specific user for a particular item \n",
    "- Introduce a new user with rating to a rating matrix and make recommendations for them \n",
    "- Create a function that will return the top n recommendations for a user \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the famous 1M movie dataset. It contains a collection of user ratings for many different movies. In the last lesson, you were exposed to working with `surprise` datasets. In this lab, you will also go through the process of reading in a dataset into the `surprise` dataset format. To begin with, load the dataset into a Pandas DataFrame. Determine which columns are necessary for your recommendation system and drop any extraneous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "new_df = df.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to transform the dataset into something compatible with `surprise`. In order to do this, you're going to need `Reader` and `Dataset` classes. There's a method in `Dataset` specifically for loading dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "# read in values as Surprise dataset \n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(new_df[['userId','movieId','rating']],reader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many users and items we have in our dataset. If using neighborhood-based methods, this will help us determine whether or not we should perform user-user or item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  610 \n",
      "\n",
      "Number of items:  9724\n"
     ]
    }
   ],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the best model \n",
    "\n",
    "Now, compare the different models and see which ones perform best. For consistency sake, use RMSE to evaluate models. Remember to cross-validate! Can you get a model with a higher average RMSE on test data than 0.869?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant libraries\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   29.6s finished\n"
     ]
    }
   ],
   "source": [
    "## Perform a gridsearch with SVD\n",
    "# ‚è∞ This cell may take several minutes to run\n",
    "param_grid = {'n_factors':[50, 100],'n_epochs': [10, 20], 'lr_all': [0.02, 0.008],\n",
    "             'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD,param_grid,measures=['rmse','mae'],cv=3,n_jobs = -1,joblib_verbose=5)\n",
    "gs.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: ({0.8830349460709405}, {'rmse': {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.008, 'reg_all': 0.4}})\n",
      "\n",
      "\n",
      "mae: ({0.6813410423868201}, {'mae': {'n_factors': 100, 'n_epochs': 20, 'lr_all': 0.02, 'reg_all': 0.4}})\n"
     ]
    }
   ],
   "source": [
    "# print out optimal parameters for SVD after GridSearch\n",
    "rms_score = {gs.best_score['rmse']}\n",
    "opt_params_rms = {'rmse': gs.best_params['rmse']}\n",
    "mae_score = {gs.best_score['mae']}\n",
    "opt_params_mae = {'mae': gs.best_params['mae']}\n",
    "print(f'rmse: {rms_score,opt_params_rms}')\n",
    "print('\\n')\n",
    "print(f'mae: {mae_score,opt_params_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9715  0.9667  0.9753  0.9707  0.9769  0.9722  0.0036  \n",
      "MAE (testset)     0.7521  0.7464  0.7543  0.7518  0.7508  0.7511  0.0026  \n",
      "Fit time          0.34    0.35    0.36    0.35    0.42    0.37    0.03    \n",
      "Test time         1.45    1.54    1.57    1.51    1.40    1.49    0.06    \n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBasic\n",
    "sim_pearson = {'name':'pearson', 'user_based':True}\n",
    "basic = KNNBasic(sim_options=sim_pearson)\n",
    "\n",
    "cv = cross_validate(basic,data,measures=['RMSE','MAE'],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.972213784188828\n"
     ]
    }
   ],
   "source": [
    "# print out the average RMSE score for the test set\n",
    "print(f\"Average RMSE: {np.mean(cv['test_rmse'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8780  0.8746  0.8828  0.8783  0.8704  0.8768  0.0041  \n",
      "MAE (testset)     0.6702  0.6691  0.6716  0.6719  0.6659  0.6698  0.0022  \n",
      "Fit time          0.61    0.61    0.62    0.67    0.75    0.65    0.06    \n",
      "Test time         1.94    1.80    1.95    2.40    2.42    2.10    0.26    \n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBaselin\n",
    "sim_pearson = {'name':'pearson', 'user_based':True}\n",
    "baseline = KNNBaseline(sim_options=sim_pearson)\n",
    "\n",
    "cv = cross_validate(baseline,data,measures=['RMSE','MAE'],verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.8768390394005008\n"
     ]
    }
   ],
   "source": [
    "# print out the average score for the test set\n",
    "print(f\"Average RMSE: {np.mean(cv['test_rmse'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off these outputs, it seems like the best performing model is the SVD model with `n_factors = 50` and a regularization rate of 0.05. Use that model or if you found one that performs better, feel free to use that to make some predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Recommendations\n",
    "\n",
    "It's important that the output for the recommendation is interpretable to people. Rather than returning the `movie_id` values, it would be far more valuable to return the actual title of the movie. As a first step, let's read in the movies to a dataframe and take a peek at what information we have about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('./ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making simple predictions\n",
    "Just as a reminder, let's look at how you make a prediction for an individual user and item. First, we'll fit the SVD model we had from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x793ab4b68ad0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=4, r_ui=None, est=2.928683972681593, details={'was_impossible': False})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction value is a tuple and each of the values within it can be accessed by way of indexing. Now let's put our knowledge of recommendation systems to do something interesting: making predictions for a new user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining User Ratings \n",
    "\n",
    "It's great that we have working models and everything, but wouldn't it be nice to get to recommendations specifically tailored to your preferences? That's what we'll be doing now. The first step is to create a function that allows us to pick randomly selected movies. The function should present users with a movie and ask them to rate it. If they have not seen the movie, they should be able to skip rating it. \n",
    "\n",
    "The function `movie_rater()` should take as parameters: \n",
    "\n",
    "* `movie_df`: DataFrame - a dataframe containing the movie ids, name of movie, and genres\n",
    "* `num`: int - number of ratings\n",
    "* `genre`: string - a specific genre from which to draw movies\n",
    "\n",
    "The function returns:\n",
    "* rating_list : list - a collection of dictionaries in the format of {'userId': int , 'movieId': int , 'rating': float}\n",
    "\n",
    "#### This function is optional, but fun :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rater(movie_df, num, genre=None):\n",
    "    rating_list = []\n",
    "    \n",
    "    # filtering the dataframe by genre\n",
    "    if genre:\n",
    "        filtered_df = movie_df[movie_df['genres'].str.contains(genre, case=False, na=False)]\n",
    "        if filtered_df.empty:\n",
    "            print(f\"No movies found for the genre '{genre}'.\")\n",
    "            return rating_list\n",
    "    else:\n",
    "        filtered_df = movie_df.copy()\n",
    "\n",
    "     # Use a random seed for reproducibility in sampling\n",
    "    random_movies = filtered_df.sample(n=min(num, len(filtered_df)), random_state=42)\n",
    "    user_id = 1700  # a new, unique user ID for the new user\n",
    "\n",
    "    for _, row in random_movies.iterrows():\n",
    "        movie_id = row['movieId']\n",
    "        movie_title = row['title']\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\n",
    "                f\"Rate the movie '{movie_title}'(1-5), or 's' to skip: \"\n",
    "            ).lower()\n",
    "\n",
    "            if user_input == 's':\n",
    "                print(f\"Skipped rating for '{movie_title}'.\")\n",
    "                break\n",
    "            try:\n",
    "                rating = float(user_input)\n",
    "                if 1.0 <= rating <= 5.0:\n",
    "                    rating_list.append({\n",
    "                        'userId': user_id,\n",
    "                        'movieId': movie_id,\n",
    "                        'rating': rating\n",
    "                    })\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid rating. Please enter a value between 1 and 5.\") \n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number or 's' to skip.\") \n",
    "    return rating_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try out the new function here!\n",
    "user_rating = movie_rater(df_movies, num=5,genre='Action')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're struggling to come up with the above function, you can use this list of user ratings to complete the next segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'userId': 1700, 'movieId': 2094, 'rating': 5.0},\n",
       " {'userId': 1700, 'movieId': 79224, 'rating': 4.0},\n",
       " {'userId': 1700, 'movieId': 111663, 'rating': 3.0},\n",
       " {'userId': 1700, 'movieId': 54908, 'rating': 4.0},\n",
       " {'userId': 1700, 'movieId': 61248, 'rating': 1.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions With the New Ratings\n",
    "Now that you have new ratings, you can use them to make predictions for this new user. The proper way this should work is:\n",
    "\n",
    "* add the new ratings to the original ratings DataFrame, read into a `surprise` dataset \n",
    "* train a model using the new combined DataFrame\n",
    "* make predictions for the user\n",
    "* order those predictions from highest rated to lowest rated\n",
    "* return the top n recommendations with the text of the actual movie (rather than just the index number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the new ratings to the original ratings DataFrame\n",
    "# convert the new ratings into  a dataframe\n",
    "user_ratings = pd.DataFrame(user_rating)\n",
    "combined_df_ratings = pd.concat([new_df,user_ratings], ignore_index=True)\n",
    "combined_df_ratings.head()\n",
    "# read in values as Surprise dataset \n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(combined_df_ratings[['userId','movieId','rating']],reader)\n",
    "trainset = data.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x793a87814690>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model using the new combined DataFrame\n",
    "# cross validating with KNNBaselin\n",
    "sim_pearson = {'name':'pearson', 'user_based':True}\n",
    "baseline = KNNBaseline(sim_options=sim_pearson)\n",
    "baseline.fit(trainset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated predictions for 9737 unrated movies\n"
     ]
    }
   ],
   "source": [
    "# make predictions for the user\n",
    "# you'll probably want to create a list of tuples in the format (movie_id, predicted_score)\n",
    "new_user_id = 1700\n",
    "# Get a set of all movie IDs from your movies DataFrame\n",
    "all_movie_ids = set(df_movies['movieId'])\n",
    "# Get a set of movie IDs that the new user has already rated\n",
    "# First, convert the list of rating dictionaries to a list of movie IDs\n",
    "rated_movie_ids = {r['movieId'] for r in user_rating}\n",
    "# Find all movies the new user has NOT rated\n",
    "unrated_movies_ids = all_movie_ids -rated_movie_ids\n",
    "# Create a list to store the predictions\n",
    "predictions_list = []\n",
    "# Looping thru all unrated movies to make predictions of the ratings\n",
    "for movie_id in unrated_movies_ids:\n",
    "    # Use the trained model to predict the rating for the new user and this movie\n",
    "    # Note: Surprise's predict method requires user and item IDs to be strings.\n",
    "    predicted_rating_obj = baseline.predict(str(new_user_id),str(movie_id))\n",
    "     # Store the movie ID and the predicted score in a tuple\n",
    "    predictions_list.append((predicted_rating_obj.iid,predicted_rating_obj.est))\n",
    "print(f'Generated predictions for {len(predictions_list)} unrated movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 Ranked Movie Predictions ---\n",
      "Movie ID: 1     | Predicted Score: 3.50\n",
      "Movie ID: 2     | Predicted Score: 3.50\n",
      "Movie ID: 3     | Predicted Score: 3.50\n",
      "Movie ID: 4     | Predicted Score: 3.50\n",
      "Movie ID: 5     | Predicted Score: 3.50\n",
      "Movie ID: 6     | Predicted Score: 3.50\n",
      "Movie ID: 7     | Predicted Score: 3.50\n",
      "Movie ID: 8     | Predicted Score: 3.50\n",
      "Movie ID: 9     | Predicted Score: 3.50\n",
      "Movie ID: 10    | Predicted Score: 3.50\n"
     ]
    }
   ],
   "source": [
    "# order the predictions from highest to lowest rated\n",
    "\n",
    "ranked_movies = sorted(predictions_list,key=lambda x:x[1],reverse=True)\n",
    "# Print the top 10 ranked movie IDs and their predicted scores\n",
    "print(\"\\n--- Top 10 Ranked Movie Predictions ---\")\n",
    "for movie_id, score in ranked_movies[:10]:\n",
    "    print(f\"Movie ID: {movie_id:<5} | Predicted Score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For the final component of this challenge, it could be useful to create a function `recommended_movies()` that takes in the parameters:\n",
    "* `user_ratings`: list - list of tuples formulated as (user_id, movie_id) (should be in order of best to worst for this individual)\n",
    "* `movie_title_df`: DataFrame \n",
    "* `n`: int - number of recommended movies \n",
    "\n",
    "The function should use a `for` loop to print out each recommended *n* movies in order from best to worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 5 Movie Recommendations ---\n",
      "1. Movie: Toy Story (1995) (Predicted Score: 3.50)\n",
      "2. Movie: Jumanji (1995) (Predicted Score: 3.50)\n",
      "3. Movie: Grumpier Old Men (1995) (Predicted Score: 3.50)\n",
      "4. Movie: Waiting to Exhale (1995) (Predicted Score: 3.50)\n",
      "5. Movie: Father of the Bride Part II (1995) (Predicted Score: 3.50)\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations using the \n",
    "def recommended_movies(user_ratings, movie_title_df, n):\n",
    "    \"\"\"\n",
    "    Prints the top n recommended movies with their titles.\n",
    "\n",
    "    Args:\n",
    "        user_ratings (list): A ranked list of tuples in the format (movie_id, predicted_score),\n",
    "                             ordered from best to worst.\n",
    "        movie_title_df (pd.DataFrame): The DataFrame containing movie IDs and titles.\n",
    "        n (int): The number of recommended movies to print.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Top {n} Movie Recommendations ---\")\n",
    "    \n",
    "    # Check for empty ratings\n",
    "    if not user_ratings:\n",
    "        print(\"No ratings available to make recommendations.\")\n",
    "        return\n",
    "\n",
    "    # Use a for loop to iterate through the top n recommendations\n",
    "    for i in range(min(n, len(user_ratings))):\n",
    "        movie_id, predicted_score = user_ratings[i]\n",
    "        \n",
    "        # Look up the movie title in the movie_title_df using the movie_id\n",
    "        movie_title = movie_title_df[movie_title_df['movieId'] == int(movie_id)]['title'].iloc[0]\n",
    "        \n",
    "        print(f\"{i + 1}. Movie: {movie_title} (Predicted Score: {predicted_score:.2f})\")\n",
    "\n",
    "# Example usage (assuming `ranked_movies` and `df_movies` are available)\n",
    "recommended_movies(ranked_movies, df_movies, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up (Optional)\n",
    "\n",
    "* Try and chain all of the steps together into one function that asks users for ratings for a certain number of movies, then all of the above steps are performed to return the top $n$ recommendations\n",
    "* Make a recommender system that only returns items that come from a specified genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "# The movie_rater() function from previous turns is a dependency for this general function.\n",
    "def movie_rater(movie_df: pd.DataFrame, num: int, genre: str = None) -> list:\n",
    "    \"\"\"\n",
    "    Prompts a new user to rate a specified number of movies.\n",
    "    \n",
    "    Args:\n",
    "        movie_df (pd.DataFrame): DataFrame containing movie IDs, titles, and genres.\n",
    "        num (int): Number of movie ratings to collect.\n",
    "        genre (str, optional): A specific genre to draw movies from for user ratings.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains the new user's rating.\n",
    "    \"\"\"\n",
    "    rating_list = []\n",
    "    \n",
    "    if genre:\n",
    "        filtered_df = movie_df[movie_df['genres'].str.contains(genre, case=False, na=False)]\n",
    "        if filtered_df.empty:\n",
    "            print(f\"No movies found for the genre '{genre}'.\")\n",
    "            return rating_list\n",
    "    else:\n",
    "        filtered_df = movie_df.copy()\n",
    "\n",
    "    random_movies = filtered_df.sample(n=min(num, len(filtered_df)), random_state=42)\n",
    "    user_id = 9999 # A high ID to avoid collision with existing users\n",
    "\n",
    "    for _, row in random_movies.iterrows():\n",
    "        movie_id = row['movieId']\n",
    "        movie_title = row['title']\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\n",
    "                f\"Rate the movie '{movie_title}' (1-5), or 's' to skip: \"\n",
    "            ).lower()\n",
    "            \n",
    "            if user_input == 's':\n",
    "                print(f\"Skipped rating for '{movie_title}'.\")\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                rating = float(user_input)\n",
    "                if 1.0 <= rating <= 5.0:\n",
    "                    rating_list.append({\n",
    "                        'userId': user_id,\n",
    "                        'movieId': movie_id,\n",
    "                        'rating': rating\n",
    "                    })\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid rating. Please enter a value between 1 and 5.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number or 's' to skip.\") \n",
    "\n",
    "    return rating_list\n",
    "\n",
    "\n",
    "def get_new_user_recommendations(\n",
    "    df_ratings: pd.DataFrame,\n",
    "    df_movies: pd.DataFrame,\n",
    "    num_ratings: int = 5,\n",
    "    n_recommendations: int = 10,\n",
    "    rating_genre: str = None,\n",
    "    recommend_genre: str = None,\n",
    "    model_params: dict = {'n_factors': 50, 'reg_all': 0.05}\n",
    "):\n",
    "    \"\"\"\n",
    "    Guides a new user through rating movies, then provides personalized recommendations.\n",
    "\n",
    "    Args:\n",
    "        df_ratings (pd.DataFrame): The original ratings dataset.\n",
    "        df_movies (pd.DataFrame): The movie metadata dataset.\n",
    "        num_ratings (int): The number of movies to ask the user to rate.\n",
    "        n_recommendations (int): The number of top recommendations to return.\n",
    "        rating_genre (str, optional): An optional genre to draw movies from for user ratings.\n",
    "        recommend_genre (str, optional): An optional genre to filter recommendations by.\n",
    "        model_params (dict, optional): Parameters for the SVD model.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame of the top n recommendations for the new user.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Get new user ratings ---\n",
    "    user_new_ratings_list = movie_rater(df_movies, num=num_ratings, genre=rating_genre)\n",
    "\n",
    "    if not user_new_ratings_list:\n",
    "        print(\"No ratings were provided by the user. Cannot generate recommendations.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get the ID of the new user from the ratings list\n",
    "    new_user_id = user_new_ratings_list[0]['userId']\n",
    "\n",
    "    # --- 2. Combine the ratings ---\n",
    "    df_new_user_ratings = pd.DataFrame(user_new_ratings_list)\n",
    "    combined_df_ratings = pd.concat([df_ratings, df_new_user_ratings], ignore_index=True)\n",
    "\n",
    "    # --- 3. Prepare and train the SVD model ---\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data_surprise = Dataset.load_from_df(combined_df_ratings[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset = data_surprise.build_full_trainset()\n",
    "    \n",
    "    model = SVD(**model_params)\n",
    "    model.fit(trainset)\n",
    "    \n",
    "    # --- 4. Identify potential movies to recommend ---\n",
    "    # Filter by a specific genre for recommendations if requested\n",
    "    if recommend_genre:\n",
    "        potential_movies = df_movies[df_movies['genres'].str.contains(recommend_genre, case=False, na=False)].copy()\n",
    "    else:\n",
    "        potential_movies = df_movies.copy()\n",
    "        \n",
    "    # Exclude movies the user has already rated\n",
    "    rated_movie_ids = {r['movieId'] for r in user_new_ratings_list}\n",
    "    unrated_movie_ids = list(set(potential_movies['movieId']) - rated_movie_ids)\n",
    "\n",
    "    # --- 5. Make predictions ---\n",
    "    predictions = [\n",
    "        model.predict(str(new_user_id), str(movie_id))\n",
    "        for movie_id in unrated_movie_ids\n",
    "    ]\n",
    "    \n",
    "    # --- 6. Rank and get top n recommendations ---\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    top_n_predictions = predictions[:n_recommendations]\n",
    "\n",
    "    # --- 7. Format and return recommendations ---\n",
    "    top_n_movie_ids = [int(p.iid) for p in top_n_predictions]\n",
    "    \n",
    "    recommended_movies_df = df_movies[df_movies['movieId'].isin(top_n_movie_ids)].copy()\n",
    "    recommended_movies_df['predicted_rating'] = recommended_movies_df['movieId'].map(\n",
    "        {int(p.iid): p.est for p in top_n_predictions}\n",
    "    )\n",
    "    \n",
    "    return recommended_movies_df.sort_values('predicted_rating', ascending=False)\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Assume df_ratings and df_movies are already loaded\n",
    "# df_ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "# df_movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "\n",
    "# Example 1: Recommend 5 movies from the 'Comedy' genre after rating 3 random movies\n",
    "# recommendations_comedy = get_new_user_recommendations(\n",
    "#     df_ratings, \n",
    "#     df_movies, \n",
    "#     num_ratings=3, \n",
    "#     n_recommendations=5, \n",
    "#     recommend_genre='Comedy'\n",
    "# )\n",
    "# print(recommendations_comedy)\n",
    "\n",
    "# Example 2: Recommend 10 movies from any genre after rating 5 movies from the 'Thriller' genre\n",
    "# recommendations_thriller = get_new_user_recommendations(\n",
    "#     df_ratings, \n",
    "#     df_movies, \n",
    "#     num_ratings=5, \n",
    "#     n_recommendations=10, \n",
    "#     rating_genre='Thriller'\n",
    "# )\n",
    "# print(recommendations_thriller)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you got the chance to implement a collaborative filtering model as well as retrieve recommendations from that model. You also got the opportunity to add your own recommendations to the system to get new recommendations for yourself! Next, you will learn how to use Spark to make recommender systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
